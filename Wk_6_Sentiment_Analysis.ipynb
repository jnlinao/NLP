{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jnlinao/NLP/blob/main/Wk_6_Sentiment_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qR5nsgvvEZFI"
      },
      "outputs": [],
      "source": [
        "!pip install -U textblob\n",
        "!pip install vaderSentiment\n",
        "!python -m textblob.download_corpora\n",
        "#!python -m spacy download en_core_web_sm\n",
        "!pip install tabulate\n",
        "!pip install spacy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Kyg53vsEZFM"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "import tabulate\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from os import path\n",
        "import seaborn as sns\n",
        "from textblob import TextBlob\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "from sklearn.metrics import confusion_matrix, precision_score, precision_recall_curve, recall_score, f1_score, accuracy_score\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXJlCwRIEZFN"
      },
      "source": [
        "# Textblob\n",
        "\n",
        "TextBlob is a Python (2 and 3) library for processing textual data. It provides a simple API for diving into common natural language processing (NLP) tasks such as part-of-speech tagging, noun phrase extraction, sentiment analysis, classification, translation, and more.\n",
        "\n",
        "https://textblob.readthedocs.io/en/dev/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZVfmpDPcEZFP"
      },
      "outputs": [],
      "source": [
        "tb = TextBlob(\"Apple is a great company.\")\n",
        "print(tb.sentiment)\n",
        "print(tb.tags)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rrHuBWKCEZFP"
      },
      "outputs": [],
      "source": [
        "tb2 = TextBlob(\"The first season of this show was brilliant and meaningful drama. It had true intellectual depth to it and managed to more than once deliver a real surprise. There were interesting characters and some exceptional acting. But that first season really told all the story there was to tell. All the good story at least.\")\n",
        "print(tb2.sentiment)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2h0JypjmEZFQ"
      },
      "outputs": [],
      "source": [
        "tb2.tags"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iu8EsSy6EZFQ"
      },
      "outputs": [],
      "source": [
        "tb2.sentiment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "foIU35pTEZFR"
      },
      "source": [
        "# Fun with Spacy\n",
        "\n",
        "### NER/Part of speech tagging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UyY7nUI2EZFS"
      },
      "outputs": [],
      "source": [
        "from spacy import displacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "doc = nlp(\"Apple is looking at buying U.K. startup for $1 billion\")\n",
        "\n",
        "for token in doc:\n",
        "   print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
        "            token.shape_, token.is_alpha, token.is_stop)\n",
        "\n",
        "displacy.render(doc, style=\"dep\")\n",
        "displacy.render(doc, style=\"ent\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "guPQBkWoEZFT"
      },
      "outputs": [],
      "source": [
        "doc = nlp(\"Thuan Pham, hired as Uber’s chief technology officer by former CEO Travis Kalanick back in 2013, is leaving the company in three weeks, the ride-share giant revealed today in an SEC filing that came out just as The Information reported that massive layoffs at Uber are being proposed to preserve some of the company’s dwindling capital reserves.\")\n",
        "displacy.render(doc, style=\"ent\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZuMEijZEZFT"
      },
      "source": [
        "# Vader \n",
        "\n",
        "VADER (Valence Aware Dictionary and sEntiment Reasoner) is a lexicon and rule-based sentiment analysis tool that is specifically attuned to sentiments expressed in social media. \n",
        "\n",
        "https://pypi.org/project/vaderSentiment/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KeomI5JTEZFU"
      },
      "outputs": [],
      "source": [
        "vader = SentimentIntensityAnalyzer()\n",
        "temp3 = vader.polarity_scores(\"Textblob is amazingly simple to use. What great fun!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3MOn_2CREZFU"
      },
      "outputs": [],
      "source": [
        "temp3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nj1VJSX1EZFU"
      },
      "source": [
        "# IMDB Dataset Sentiment Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RdZ-M17LEZFV"
      },
      "outputs": [],
      "source": [
        "# Load in the dataframe\n",
        "df = pd.read_csv(\"IMDB_Dataset.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-yaoJLa4EZFV"
      },
      "outputs": [],
      "source": [
        "df.axes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dJ7vxLzZEZFV"
      },
      "outputs": [],
      "source": [
        "print(df.review[0], \"\\n\", df.sentiment[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-hiNFHrBEZFV"
      },
      "outputs": [],
      "source": [
        "len(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EG2dMM0VEZFW"
      },
      "outputs": [],
      "source": [
        "df[0:10].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DcfwEKUOEZFW"
      },
      "outputs": [],
      "source": [
        "def detect_tb_polarity(text):\n",
        "    return TextBlob(text).sentiment.polarity\n",
        "\n",
        "def detect_tb_subjectivity(text):\n",
        "    return TextBlob(text).sentiment.subjectivity\n",
        "\n",
        "def detect_vader_pos(text):\n",
        "    return vader.polarity_scores(text)['pos']\n",
        "    \n",
        "def detect_vader_neg(text):\n",
        "    return vader.polarity_scores(text)['neg']\n",
        "\n",
        "def detect_vader_comp(text):\n",
        "    return vader.polarity_scores(text)['compound']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3tMH5_t7EZFW"
      },
      "outputs": [],
      "source": [
        "vader.polarity_scores(df.review[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ypB2HCFEZFW"
      },
      "outputs": [],
      "source": [
        "df_sample = df[0:1000].copy()\n",
        "df_sample['tb_polarity'] = df_sample.review.apply(detect_tb_polarity)\n",
        "df_sample['tb_subjectivity'] = df_sample.review.apply(detect_tb_subjectivity)\n",
        "\n",
        "vader = SentimentIntensityAnalyzer()\n",
        "df_sample['vader_pos'] = df_sample.review.apply(detect_vader_pos)\n",
        "df_sample['vader_neg'] = df_sample.review.apply(detect_vader_neg)\n",
        "df_sample['vader_comp'] = df_sample.review.apply(detect_vader_comp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DPYSKSr-EZFX"
      },
      "outputs": [],
      "source": [
        "df_sample.head(25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Fi7cOFuEZFX"
      },
      "outputs": [],
      "source": [
        "modelLR1 = LogisticRegression()\n",
        "\n",
        "modelLR1.fit(df_sample.iloc[:,2:6], df_sample.iloc[:,1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_xjCi09rEZFX"
      },
      "outputs": [],
      "source": [
        "sent_pred = modelLR1.predict(df_sample.iloc[:,2:6])\n",
        "confusion_matrix(df_sample.sentiment, sent_pred)\n",
        "print(\"F1 score:\", f1_score(df_sample.sentiment, sent_pred, average='micro'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mx-Hk52FEZFX"
      },
      "outputs": [],
      "source": [
        "np.corrcoef(df_sample.vader_pos, df_sample.tb_polarity)[0,1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UahmLdmjEZFY"
      },
      "outputs": [],
      "source": [
        "sns.set(style=\"whitegrid\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IVaWTXCXEZFY"
      },
      "outputs": [],
      "source": [
        "ax = sns.violinplot(x=\"sentiment\", y=\"tb_polarity\", data=df_sample)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WBY_ltdIEZFY"
      },
      "outputs": [],
      "source": [
        "ax = sns.violinplot(x=\"sentiment\", y=\"vader_comp\", data=df_sample)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q51W0AGZEZFY"
      },
      "outputs": [],
      "source": [
        "ax = sns.violinplot(x=\"sentiment\", y=\"vader_pos\", data=df_sample)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zF5jBI69EZFY"
      },
      "outputs": [],
      "source": [
        "tb_pred = pd.cut(df_sample['tb_polarity'], bins=2, labels=[\"negative\", \"positive\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p83SYr9cEZFY"
      },
      "outputs": [],
      "source": [
        "print(\"Confusion Matrix:\\n\", confusion_matrix(df_sample.sentiment, tb_pred))\n",
        "print(\"F1 score:\", f1_score(df_sample.sentiment, tb_pred, average='micro'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gk225fgiEZFZ"
      },
      "outputs": [],
      "source": [
        "v_pred = np.where(df_sample['vader_comp'] > 0.0, \"positive\", \"negative\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qYr8gChvEZFZ"
      },
      "outputs": [],
      "source": [
        "print(\"Confusion Matrix:\\n\", confusion_matrix(df_sample.sentiment, v_pred))\n",
        "print(\"F1 score:\", f1_score(df_sample.sentiment, v_pred, average='micro'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kuTKwArzEZFZ"
      },
      "source": [
        "## Datasets\n",
        "Here, 70% of the original data are used for training models, and the rest are for test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EzsdLo-0EZFZ"
      },
      "outputs": [],
      "source": [
        "df_sample = df[0:1000].copy()\n",
        "train_sample = int(len(df_sample)*0.7)\n",
        "train = df_sample[0:(train_sample)]\n",
        "test = df_sample[(train_sample+1):len(df_sample)]\n",
        "print('train data size:', len(train))\n",
        "print('test data size:', len(test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NxW1DrLpEZFZ"
      },
      "outputs": [],
      "source": [
        "tv = TfidfVectorizer(stop_words='english', lowercase=True);\n",
        "tv.fit(train.review)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lzLls7yCEZFa"
      },
      "outputs": [],
      "source": [
        "modelNB = MultinomialNB(alpha=1)\n",
        "modelNB.fit(tv.transform(train.review), train.sentiment)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sft4ZmbUEZFa"
      },
      "outputs": [],
      "source": [
        "nb_pred = modelNB.predict(tv.transform(test.review))\n",
        "\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(test.sentiment, nb_pred))\n",
        "print(\"F1 score:\", f1_score(test.sentiment, nb_pred, average='micro'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7dTUL4VrEZFa"
      },
      "outputs": [],
      "source": [
        "modelLR = LogisticRegression(C=1, solver='liblinear')\n",
        "modelLR.fit(tv.transform(train.review), train.sentiment)\n",
        "\n",
        "lr_pred = modelLR.predict(tv.transform(test.review))\n",
        "\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(test.sentiment, lr_pred))\n",
        "print(\"F1 score:\", f1_score(test.sentiment, lr_pred, average='micro'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aXE0D9D-EZFa"
      },
      "source": [
        "## Understandig emotions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z56iT3ehEZFa"
      },
      "outputs": [],
      "source": [
        "# Load in the dataframe\n",
        "df_emotions = pd.read_csv(\"emotions.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MvHHo6V7EZFa"
      },
      "outputs": [],
      "source": [
        "df_emotions.head(25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7GT_IxIsEZFb"
      },
      "outputs": [],
      "source": [
        "df_emotions.sentiment.unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pJ-aoJREEZFb"
      },
      "outputs": [],
      "source": [
        "len(df_emotions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4eUa__ReEZFb"
      },
      "outputs": [],
      "source": [
        "# Create the test and training sets\n",
        "\n",
        "train_samples = int(len(df_emotions)*0.8)\n",
        "\n",
        "train = df_emotions[0:train_samples]\n",
        "test = df_emotions[train_samples+1:len(df_emotions)]\n",
        "print('train data size:', len(train))\n",
        "print('test data size:', len(test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R-F6_1XBEZFb"
      },
      "outputs": [],
      "source": [
        "#Some descriptive analysis\n",
        "train['sentiment'].value_counts().plot(kind='bar')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zFKnMfNAEZFb"
      },
      "outputs": [],
      "source": [
        "#Some descriptive analysis\n",
        "test['sentiment'].value_counts().plot(kind='bar')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7GDUki0tEZFb"
      },
      "outputs": [],
      "source": [
        "tv = TfidfVectorizer(ngram_range=(1,3), stop_words='english')\n",
        "tv.fit(train.content)\n",
        "\n",
        "#modelELR = LogisticRegression(C=0.1)\n",
        "modelELR = MultinomialNB(alpha=0.1)\n",
        "modelELR.fit(tv.transform(train.content), train.sentiment)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "05hIAH7jEZFb"
      },
      "outputs": [],
      "source": [
        "elr_pred = modelELR.predict(tv.transform(train.content))\n",
        "\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(train.sentiment, elr_pred))\n",
        "print(\"F1 score:\", f1_score(train.sentiment, elr_pred, average='micro'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cbdqLWUUEZFc"
      },
      "outputs": [],
      "source": [
        "print(train.content[20])\n",
        "modelELR.predict(tv.transform(train.content[20:21]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pY1u7YZbEZFc"
      },
      "outputs": [],
      "source": [
        "print(train.content[40])\n",
        "modelELR.predict(tv.transform(train.content[40:41]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a6kQHvPmEZFc"
      },
      "outputs": [],
      "source": [
        "def plot_confusion_matrix(preds, labels):\n",
        "  class_labels = np.unique(df_emotions.sentiment)\n",
        "  class_size = len(class_labels)\n",
        "  cnf_mat = confusion_matrix(labels, preds)                            #Computes confusion_matrix\n",
        "  cnf_mat = cnf_mat.astype('float') / (cnf_mat.sum(axis=1)[:, np.newaxis]+1)\n",
        "  plt.imshow(cnf_mat, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "  #plt.xticks(np.arange(class_size), np.arange(1, class_size + 1), class_labels)\n",
        "  plt.xticks(np.arange(class_size), labels=class_labels, rotation='vertical')\n",
        "  plt.yticks(np.arange(class_size), labels=class_labels)\n",
        "  #plt.yticks(np.arange(class_size), np.arange(1, class_size + 1), class_labels)\n",
        "  plt.title('Confusion matrix of the classifier')\n",
        "  plt.xlabel('True Label')\n",
        "  plt.ylabel('Predicted Label')\n",
        "  plt.title('Confusion Matrix')\n",
        "  plt.colorbar()\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ROSrYctEZFc"
      },
      "outputs": [],
      "source": [
        "plot_confusion_matrix(train.sentiment, elr_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Er_Bn5CVEZFc"
      },
      "outputs": [],
      "source": [
        "elr_pred = modelELR.predict(tv.transform(test.content))\n",
        "\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(test.sentiment, elr_pred))\n",
        "print(\"F1 score:\", f1_score(test.sentiment, elr_pred, average='micro'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5L-zq3ayEZFc"
      },
      "outputs": [],
      "source": [
        "plot_confusion_matrix(test.sentiment, elr_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8QebO2IPEZFc"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "Wk 6 Sentiment Analysis.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}