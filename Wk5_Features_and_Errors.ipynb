{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jnlinao/NLP/blob/main/Wk5_Features_and_Errors.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmpodQkfokCX"
      },
      "source": [
        "## Import packages\n",
        "Make sure you installed ***eli5***, ***tabulate***, ***sklearn***, ***matplotlib*** and ***numpy*** if you use your local machine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQWB7ST6fYj6",
        "outputId": "e5ac2248-bee4-4b47-9ddf-f8e594bad352"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: eli5 in /usr/local/lib/python3.7/dist-packages (0.11.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from eli5) (1.4.1)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (from eli5) (0.10.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20 in /usr/local/lib/python3.7/dist-packages (from eli5) (1.0.2)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.7/dist-packages (from eli5) (0.8.9)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from eli5) (1.21.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from eli5) (2.11.3)\n",
            "Requirement already satisfied: attrs>16.0.0 in /usr/local/lib/python3.7/dist-packages (from eli5) (21.4.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from eli5) (1.15.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20->eli5) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20->eli5) (3.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->eli5) (2.0.1)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (0.8.9)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (2.2.4)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.9.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.23.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.7)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy) (57.4.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.6)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.21.6)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.6)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (7.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.64.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy) (3.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy) (4.2.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n"
          ]
        }
      ],
      "source": [
        "!pip install eli5\n",
        "!pip install tabulate\n",
        "!pip install spacy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gxD_3fs1tX_E"
      },
      "outputs": [],
      "source": [
        "import eli5\n",
        "import tabulate\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import sklearn\n",
        "import spacy\n",
        "from sklearn import datasets\n",
        "from sklearn.pipeline import FeatureUnion\n",
        "from sklearn.pipeline import Pipeline, make_pipeline\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import confusion_matrix, precision_score, precision_recall_curve, recall_score, f1_score\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LP6WvBXfOHyD"
      },
      "source": [
        "## Fun with Spacy\n",
        "NER/Part of speech tagging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "LIm4AjenOHyE",
        "outputId": "8e620ef4-0a36-43a6-d499-53c1e611a6d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Apple Apple PROPN NNP nsubj Xxxxx True False\n",
            "is be AUX VBZ aux xx True True\n",
            "looking look VERB VBG ROOT xxxx True False\n",
            "at at ADP IN prep xx True True\n",
            "buying buy VERB VBG pcomp xxxx True False\n",
            "U.K. U.K. PROPN NNP compound X.X. False False\n",
            "startup startup NOUN NN dobj xxxx True False\n",
            "for for ADP IN prep xxx True True\n",
            "$ $ SYM $ quantmod $ False False\n",
            "1 1 NUM CD compound d False False\n",
            "billion billion NUM CD pobj xxxx True False\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\\n<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\\n    Apple\\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\\n</mark>\\n is looking at buying \\n<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\\n    U.K.\\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\\n</mark>\\n startup for \\n<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\\n    $1 billion\\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\\n</mark>\\n</div>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "from spacy import displacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "doc = nlp(\"Apple is looking at buying U.K. startup for $1 billion\")\n",
        "\n",
        "for token in doc:\n",
        "   print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
        "            token.shape_, token.is_alpha, token.is_stop)\n",
        "\n",
        "displacy.render(doc, style=\"dep\")\n",
        "displacy.render(doc, style=\"ent\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "id": "J8iP09mzOHyE",
        "outputId": "0db3433b-1a0e-4e71-e4de-0570861dd263"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\\n<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\\n    Thuan Pham\\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\\n</mark>\\n, hired as \\n<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\\n    Uber\\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\\n</mark>\\n’s chief technology officer by former CEO \\n<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\\n    Travis Kalanick\\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\\n</mark>\\n back in \\n<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\\n    2013\\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\\n</mark>\\n, is leaving the company in \\n<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\\n    three weeks\\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\\n</mark>\\n, the ride-share giant revealed \\n<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\\n    today\\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\\n</mark>\\n in an \\n<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\\n    SEC\\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\\n</mark>\\n filing that came out just as The Information reported that massive layoffs at \\n<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\\n    Uber\\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\\n</mark>\\n are being proposed to preserve some of the company’s dwindling capital reserves.</div>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "doc = nlp(\"Thuan Pham, hired as Uber’s chief technology officer by former CEO Travis Kalanick back in 2013, is leaving the company in three weeks, the ride-share giant revealed today in an SEC filing that came out just as The Information reported that massive layoffs at Uber are being proposed to preserve some of the company’s dwindling capital reserves.\")\n",
        "displacy.render(doc, style=\"ent\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U0vF7uNdox7d"
      },
      "source": [
        "# Feature Engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "orCxJPAWIxqk"
      },
      "source": [
        "## Prepare dataset and Pick two classes\n",
        "Your two classes should be similar, but opposite in some sense"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CPSdjUHDoSnf",
        "outputId": "54ab1785-dab4-43b6-a01c-a28e9b67669f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train data size: 1168\n",
            "test data size: 777\n"
          ]
        }
      ],
      "source": [
        "# categories = ['alt.atheism', 'soc.religion.christian']\n",
        "categories = ['comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware']\n",
        "# categories = ['rec.sport.baseball', 'rec.sport.hockey']\n",
        "# 'alt.atheism','comp.graphics','comp.os.ms-windows.misc','comp.sys.ibm.pc.hardware',\n",
        "# 'comp.sys.mac.hardware','comp.windows.x', 'misc.forsale', 'rec.autos',  \n",
        "# 'rec.motorcycles',  'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt',\n",
        "# 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns',\n",
        "# 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc'\n",
        "train = sklearn.datasets.fetch_20newsgroups(subset='train', categories=categories, remove=('headers', 'footers', 'quotes'),)\n",
        "test = sklearn.datasets.fetch_20newsgroups(subset='test', categories=categories, remove=('headers', 'footers', 'quotes'),)\n",
        "print('train data size:', len(train.data))\n",
        "print('test data size:', len(test.data))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u4mRc1xYI10a"
      },
      "source": [
        "## Design your own features\n",
        "This is also warm-up for HW2 :)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qiSoWKntytVh"
      },
      "outputs": [],
      "source": [
        "class CustomFeats(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self):\n",
        "      self.feat_names = set()\n",
        "\n",
        "    def fit(self, x, y=None):\n",
        "        return self\n",
        "\n",
        "    @staticmethod\n",
        "    def features(review):\n",
        "      return {\n",
        "          'bias' : 4.0,\n",
        "          'RAM' : test_binary_feature(review),\n",
        "          'mac': mac_binary_feature(review),\n",
        "          'apple': apple_binary_feature(review),\n",
        "          'IBM': ibm_feature(review)\n",
        "      }\n",
        "\n",
        "    def get_feature_names(self):\n",
        "        return list(self.feat_names)\n",
        "      \n",
        "    def transform(self, reviews):\n",
        "      feats = []\n",
        "      for review in reviews:\n",
        "        f = self.features(review)\n",
        "        [self.feat_names.add(k) for k in f] \n",
        "        feats.append(f)\n",
        "      return feats\n",
        "    \n",
        "feats = make_pipeline(CustomFeats())\n",
        "#feats = make_pipeline(CustomFeats(), DictVectorizer())\n",
        "#feats = FeatureUnion([\n",
        "#     ('custom', make_pipeline(CustomFeats(), DictVectorizer())),\n",
        "#     ('bag_of_words', CountVectorizer())\n",
        "# ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_bsKLnDVd4Ec",
        "outputId": "e1b74765-f019-459e-dc6c-99d07e9d6518"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         comp.sys.ibm.pc.hardware    comp.sys.mac.hardware\n",
            "-----  --------------------------  -----------------------\n",
            "True                            2                       24\n",
            "False                         588                      554\n"
          ]
        }
      ],
      "source": [
        "def test_binary_feature(review):\n",
        "  target_word = 'RAM'\n",
        "  threshold = 0\n",
        "  words = filter(lambda r: r.find(target_word) is not -1, review.split(' '))\n",
        "  count = len(list(words))\n",
        "  return count > threshold\n",
        "\n",
        "def mac_binary_feature(review):\n",
        "  target_word = 'mac'\n",
        "  threshold = 0\n",
        "  words = filter(lambda r: r.find(target_word) is not -1, review.split(' '))\n",
        "  count = len(list(words))\n",
        "  if count > threshold:\n",
        "        return 1\n",
        "  else:\n",
        "        return 0\n",
        "\n",
        "def ibm_feature(review):\n",
        "  target_word = 'IBM'\n",
        "  threshold = 0\n",
        "  words = filter(lambda r: r.find(target_word) is not -1, review.split(' '))\n",
        "  count = len(list(words))\n",
        "  return count\n",
        "\n",
        "def apple_binary_feature(review):\n",
        "  target_word = 'apple'\n",
        "  threshold = 0\n",
        "  words = filter(lambda r: r.find(target_word) is not -1, review.split(' '))\n",
        "  count = len(list(words))\n",
        "  if count > threshold:\n",
        "        return 1\n",
        "  else:\n",
        "        return 0\n",
        "\n",
        "def show_table(train, Ω):\n",
        "  matrix = np.zeros((2, 2))\n",
        "  for i in range(len(train.data)):\n",
        "    flag = Ω(train.data[i])\n",
        "    index = 0 if flag else 1\n",
        "    matrix[index][train.target[i]] += 1\n",
        "  print(tabulate.tabulate([['True', matrix[0][0], matrix[0][1]], ['False', matrix[1][0], matrix[1][1]]], headers=['', train.target_names[0], train.target_names[1]]))\n",
        "\n",
        "\n",
        "show_table(train, lambda r: r.find('apple') is not -1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dkmr2r2pOHyI"
      },
      "outputs": [],
      "source": [
        "train.custvector = feats.fit_transform(train.data)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train.custvector[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XyKQ7nymXuTU",
        "outputId": "65de1ef8-c866-4dd1-b236-9a3f2b5e2c15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'IBM': 0, 'RAM': False, 'apple': 0, 'bias': 4.0, 'mac': 0}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CvvRGQ1vI-JY"
      },
      "source": [
        "## Number of Features\n",
        "(#sample, #features)  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n2NpJzCEUV_M"
      },
      "outputs": [],
      "source": [
        "train.vecs = feats.fit_transform(train.data)\n",
        "test.vecs = feats.transform(test.data)\n",
        "train.vecs.shape, test.vecs.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CW4hHdcFOHyJ"
      },
      "outputs": [],
      "source": [
        "feats.steps[0][1].get_feature_names()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wXus8_yyOHyJ"
      },
      "outputs": [],
      "source": [
        "print(train.vecs[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v467yN50kV4a"
      },
      "source": [
        "What if we add\n",
        "- number-based feature with threshold\n",
        "- number-based feature  \n",
        "\n",
        "to ***features*** function?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p1Q-gs7TV_-Z"
      },
      "outputs": [],
      "source": [
        "lr_model = LogisticRegression(C=1)\n",
        "lr_model.fit(train.vecs,train.target)\n",
        "#lr_model = make_pipeline(CountVectorizer(), LogisticRegression())\n",
        "#lr_model.fit(train.data, train.target)\n",
        "\n",
        "train_preds = lr_model.predict(train.vecs)\n",
        "train_f1 = f1_score(train.target, train_preds, average='micro')\n",
        "test_preds = lr_model.predict(test.vecs)\n",
        "test_f1 = f1_score(test.target, test_preds, average='micro')\n",
        "print(train_f1, test_f1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cZLyUI6tOHyK"
      },
      "outputs": [],
      "source": [
        "eli5.show_weights(lr_model, top=10, vec=feats.steps[0][1], target_names=test.target_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fN9pOPfSOHyL"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xUysugxv_9gW"
      },
      "source": [
        "## False negative and positive examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ph9VYtPWSaO"
      },
      "outputs": [],
      "source": [
        "def show_false_negative(test_preds, test):\n",
        "  fn_idxs = list(filter(lambda idx: test_preds[idx] != test.target[idx] and test_preds[idx] == 0, range(len(test_preds))))\n",
        "  if len(fn_idxs) == 0: return None\n",
        "  fidx = np.random.randint(len(fn_idxs))\n",
        "  return test.data[fn_idxs[fidx]]\n",
        "\n",
        "def show_false_positive(test_preds, test, size=2):\n",
        "  fn_idxs = list(filter(lambda idx: test_preds[idx] != test.target[idx] and test_preds[idx] == 1, range(len(test_preds))))\n",
        "  if len(fn_idxs) == 0: return None\n",
        "  fidx = np.random.randint(len(fn_idxs))\n",
        "  return test.data[fn_idxs[fidx]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VaLQfyhLZLQQ"
      },
      "outputs": [],
      "source": [
        "show_false_negative(test_preds, test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iJaZJ82KcXbG"
      },
      "outputs": [],
      "source": [
        "show_false_positive(test_preds, test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJqkcL-avfFS"
      },
      "source": [
        "# Error Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TRMr_inLzEmU"
      },
      "outputs": [],
      "source": [
        "# categories = ['alt.atheism', 'soc.religion.christian']\n",
        "categories = ['comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware']\n",
        "# categories = ['rec.sport.baseball', 'rec.sport.hockey']\n",
        "# 'alt.atheism','comp.graphics','comp.os.ms-windows.misc','comp.sys.ibm.pc.hardware',\n",
        "# 'comp.sys.mac.hardware','comp.windows.x', 'misc.forsale', 'rec.autos',  \n",
        "# 'rec.motorcycles',  'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt',\n",
        "# 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns',\n",
        "# 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc'\n",
        "train = sklearn.datasets.fetch_20newsgroups(subset='train', categories=categories)\n",
        "test = sklearn.datasets.fetch_20newsgroups(subset='test', categories=categories)\n",
        "print('train data size:', len(train.data))\n",
        "print('test data size:', len(test.data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DrDMLmHMzh80"
      },
      "outputs": [],
      "source": [
        "lr_model = LogisticRegression(C=0.1)\n",
        "vec = CountVectorizer()\n",
        "pipe = make_pipeline(vec, lr_model)\n",
        "pipe.fit(train.data, train.target)\n",
        "train_preds = pipe.predict(train.data)\n",
        "train_f1 = f1_score(train.target, train_preds, average='micro')\n",
        "test_preds = pipe.predict(test.data)\n",
        "test_f1 = f1_score(test.target, test_preds, average='micro')\n",
        "train_f1, test_f1  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dfzAhIjAOHyM"
      },
      "outputs": [],
      "source": [
        "eli5.show_weights(pipe, top=10, target_names=test.target_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8VnhO46u0Giw"
      },
      "outputs": [],
      "source": [
        "idx = 10\n",
        "x = test.data[idx]\n",
        "#print(test.data[idx])\n",
        "print(test.target_names[test.target[idx]])\n",
        "eli5.show_prediction(lr_model, test.data[idx], vec=vec, target_names=test.target_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KFukhIfZOHyN"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vxaosjf1RWdB"
      },
      "outputs": [],
      "source": [
        "rf_model = RandomForestClassifier()\n",
        "vec = CountVectorizer()\n",
        "pipe = make_pipeline(vec, rf_model)\n",
        "pipe.fit(train.data, train.target)\n",
        "train_preds = pipe.predict(train.data)\n",
        "train_f1 = f1_score(train.target, train_preds, average='micro')\n",
        "test_preds = pipe.predict(test.data)\n",
        "test_f1 = f1_score(test.target, test_preds, average='micro')\n",
        "train_f1, test_f1  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Vdr4pkCRqi5"
      },
      "outputs": [],
      "source": [
        "eli5.show_weights(pipe, top=10, target_names=test.target_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WQ8AswYkSBZD"
      },
      "outputs": [],
      "source": [
        "idx = 1\n",
        "x = test.data[idx]\n",
        "print(test.target_names[test.target[idx]])\n",
        "eli5.show_prediction(rf_model, test.data[idx], vec=vec, target_names=test.target_names, top=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SfzNZ-vrOHyN"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Wk5 - Features and Errors.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}